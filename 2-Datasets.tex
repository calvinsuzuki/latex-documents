\chapter{\textit{Datasets}}\label{chp:datasets}

\section{Obtenção e pré-processamento dos dados}

Os \textit{datasets} presentes na literatura são obtidos a partir da colagem de eletrodos em diversos locais na escalpe do indivíduo para a obtenção dos dados, resultando em um registro de vários sinais de tensão cerebral em um intervalo de tempo. Cada \textit{dataset} possui seus próprios parâmetros como: taxa de amostragem; tamanho do intervalo; quantidade de eletrodos; e etc. Vale salientar que esses valores requerem pré-processamento antes de serem utilizados e validados por um método de aprendizado, por exemplo, para remoção de ruídos oriundos da imprecisão técnica do aparelho ou oscilações na rede elétrica.

No processo de limpeza são utilizados filtros de passa-alta, removendo componentes CC dos sinais e também os desvios, e de passa-baixa, eliminando as peças de alta frequência dos dados. Além dessas, também podem ser aplicadas outras formas, dependendo das imprevisões ocorridas durante a etapa de monitoramento. Um exemplo é a aplicação da técnica de correção de artefatos de Eletrooculograma (EOG), que pode ser necessário se o sujeito sob gravação estiver com os olhos aberto. \cite{EEGMANIQUINS}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.7\textwidth]{figuras/exemplo_eeg.jpg}
    \caption{Exemplo de um Eletroencefalograma (EEG).}
    \label{fig:exemplo_eeg}
\end{figure}

O próximo procedimento é a interpretação dos dados e, consequentemente, a extração de recursos. Dado um EEG, essa tarefa é complicada para ser realizada a olho nu (figura \ref{fig:exemplo_eeg}). Exatamente por isto, foram desenvolvidos vários algoritmos complexos de processamento que fazem esse procedimento e separam as características no domínio do tempo e da frequência.

Como resultado da etapa anterior, deve-se obter uma alta gama de propriedades. Devido a isto, se faz necessário um procedimento de seleção de recursos, visando buscar apenas as características necessárias para a modelagem do problema.

Somente após a execução dos roteiros anteriores, os dados estarão prontos para alimentarem nossos modelos de aprendizado de máquina. Vale ressaltar que os processos de obtenção requerem anos ou até mesmo décadas para que acumulem uma quantidade suficiente de valores e, com isso, possibilitar a alimentação dos algorítimos. Entretanto, isso é algo que vem sendo armazenado há muito tempo e a melhor parte é que está disponível ao público. Na próxima seção, falaremos dos \textit{datasets open-sources} existentes na internet.

\section{Datasets existentes}

\subsection{CHB-MIT Scalp EEG \textit{Database}}

Esse banco de dados, consiste em registros de EEG de pacientes pediátricos com convulsões intratáveis. Os indivíduos foram monitorados por vários dias e, após a retirada da medicação anticonvulsivante, caracterizamos suas convulsões e avaliamos sua candidatura à intervenção cirúrgica \cite{CHB-MIT}.

%falar como os dados estão organizados
Todos os sinais foram coletados em 256 amostras por segundo com resolução de 16 bits. A maioria dos arquivos contém 23 sinais de EEG (24 ou 26 em alguns casos). O sistema \textit{International 10-20} de posições e nomenclatura dos eletrodos de EEG foi usado para esses registros.

\subsection{Outros \textit{datasets}}

Existe um repositório no \textit{GitHub} com uma ampla quantidade de \textit{datasets} sobre EEG's \cite{GITREPOSITORIO} que estão separados por categorias como Motor-Imagem; Emoção-Reconhecimento; Potenciais Relacionados a Erros; e entre outros. Destacamos a possibilidade de utilizarmos o \textit{dataset} de convulsões, visto que ela é um dos principais sintomas da crise epiléptica. Obviamente, devemos lembrar que uma pessoa pode não apresentar esse sintoma durante um ataque, portanto esse banco de dados sozinho é ineficiente para o treinamento, contudo, ainda podemos utilizá-lo para testar a acurácia do modelo, após treinado.